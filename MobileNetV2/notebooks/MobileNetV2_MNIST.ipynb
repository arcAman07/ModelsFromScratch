{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetV2- MNIST",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EnnIiVn87dUs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "import os\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "from torchvision import transforms, utils, datasets\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trans = transforms.Lambda(lambda x: x.repeat(1, 1, 3) if x.size(2)==1 else x)"
      ],
      "metadata": {
        "id": "bNP5JC_SRDbP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(224, 224, 1)\n",
        "out = trans(x)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rOqwe5PTWJ7",
        "outputId": "d4aa3356-2c4c-4663-dfd7-2d4ef0d3e986"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([224, 224, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NoneTransform(object):\n",
        "    ''' Does nothing to the image. To be used instead of None '''\n",
        "    \n",
        "    def __call__(self, image):       \n",
        "        return image"
      ],
      "metadata": {
        "id": "OGgL4IgNm80k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x),\n",
        "    ]\n",
        "))\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.size(0)==1 else x),\n",
        "    ]\n",
        "))\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "Vx_iKjgR7hr9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}"
      ],
      "metadata": {
        "id": "T6faqwGm7hu3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]"
      ],
      "metadata": {
        "id": "5aPIlZhq7h0l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6bUgTtHnaq-",
        "outputId": "310dcc80-52b9-4c81-8443-a200afd2e2db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jabgRKnEndbj",
        "outputId": "428ac6a5-b672-44ba-c211-91341183f7ce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Model architecture: Inverted Residual Block (IRB)\n",
        "\n",
        "Input( b * h * c)    Operator    t( expansion factor / Width multiplier)    c( channels )    s( stride )    n( Repeating layers )\n",
        "\n",
        "224 ^2 * 3         Conv2d               None                                 32                2                 1\n",
        "\n",
        "112 ^2 * 32        Bottleneck           1                                    16                1                 1\n",
        "\n",
        "112 ^2 * 16        Bottleneck           6                                    24                2                 2\n",
        "\n",
        "56 ^2 * 24         Bottleneck           6                                    32                2                 3\n",
        "\n",
        "28 ^2 * 32         Bottleneck           6                                    64                2                 4\n",
        "\n",
        "14 ^2 * 64         Bottleneck           6                                    96                1                 3\n",
        "\n",
        "14 ^2 * 96         Bottleneck           6                                    160               2                 3\n",
        "\n",
        "7 ^2 * 160         Bottleneck           6                                    320               1                 1\n",
        "\n",
        "7 ^2 * 320         Conv2d 1X1           None                                 1280              1                 1\n",
        "\n",
        "7 ^2 * 1280        avgPool 7*7          None                                  -                -                 -\n",
        "\n",
        "1 ^2 * 1280        Conv2d 1X1           None                                  k                -                 -\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Model : Linear Bottleneck\n",
        "\n",
        "Input                        Operator                   Output\n",
        "\n",
        "h * w * k       Conv2d 1*1 , BatchNorm2d, Relu6        h * w * tk\n",
        "\n",
        "h * w * tk      Depthwise Conv2d 3*3 stride = s , BatchNorm1d, Relu6        h/s * w/s * tk\n",
        "\n",
        "h/s * w/s * tk  Pointwise Conv2d 1*1 , BatchNorm2d, Relu6                   h/s * w/s * d'\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "t3nzrhUUlDdi",
        "outputId": "b4a52de5-b329-48b1-bda8-6f11692760ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nModel : Linear Bottleneck\\n\\nInput                        Operator                   Output\\n\\nh * w * k       Conv2d 1*1 , BatchNorm2d, Relu6        h * w * tk\\n\\nh * w * tk      Depthwise Conv2d 3*3 stride = s , BatchNorm1d, Relu6        h/s * w/s * tk\\n\\nh/s * w/s * tk  Pointwise Conv2d 1*1 , BatchNorm2d, Relu6                   h/s * w/s * d'\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "        \n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "TrKX_PeqqTh8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearBottleneck(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride, expansion, groups, bias=False):\n",
        "    super(LinearBottleneck, self).__init__()\n",
        "    self.stride = stride\n",
        "    self.expansion = expansion\n",
        "    self.groups = groups\n",
        "    self.sequential_conv = nn.Sequential(\n",
        "      nn.Conv2d(in_channels, in_channels * expansion, kernel_size=1, bias=bias, groups=1),\n",
        "      nn.BatchNorm2d(in_channels * expansion),\n",
        "      nn.ReLU6(inplace=True),\n",
        "    )\n",
        "    self.depthwise_conv = nn.Sequential(\n",
        "      nn.Conv2d(in_channels * expansion, in_channels * expansion, kernel_size=3, stride=stride, padding=1, bias=bias, groups=groups),\n",
        "      nn.BatchNorm2d(in_channels * expansion),\n",
        "      nn.ReLU6(inplace=True),\n",
        "    )\n",
        "    self.pointwise_conv = nn.Sequential(\n",
        "      nn.Conv2d(in_channels * expansion, out_channels, kernel_size=1, bias=bias, groups=1),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU6(inplace=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.sequential_conv(x)\n",
        "    x = self.depthwise_conv(x)\n",
        "    x = self.pointwise_conv(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "MwFsVtry7h5p"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MobileNetV2(ImageClassificationBase):\n",
        "  def __init__(self, num_classes=10, width_mult=1.0, groups=8, bias=False):\n",
        "    super(MobileNetV2, self).__init__()\n",
        "    self.width_mult = width_mult\n",
        "    self.groups = groups\n",
        "    self.bias = bias\n",
        "    self.first_layer = nn.Sequential(\n",
        "      nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=bias),\n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.ReLU6(inplace=True),\n",
        "    )\n",
        "    self.first_bottleneck = nn.Sequential(\n",
        "      LinearBottleneck(32, 16, 1, 1, groups=32, bias=bias),\n",
        "    )\n",
        "    self.second_bottleneck = nn.Sequential(\n",
        "      LinearBottleneck(16, 24, 2, 6, groups=16, bias=bias),\n",
        "      LinearBottleneck(24, 24, 1, 6, groups=24, bias=bias),\n",
        "    )\n",
        "    self.third_bottleneck = nn.Sequential(\n",
        "      LinearBottleneck(24, 32, 2, 6, groups=24, bias=bias),\n",
        "      LinearBottleneck(32, 32, 1, 6, groups=32, bias=bias),\n",
        "      LinearBottleneck(32, 32, 1, 6, groups=32, bias=bias),\n",
        "    )\n",
        "    self.fourth_bottleneck = nn.Sequential(\n",
        "      LinearBottleneck(32, 64, 2, 6, groups=32, bias=bias),\n",
        "      LinearBottleneck(64, 64, 1, 6, groups=64, bias=bias),\n",
        "      LinearBottleneck(64, 64, 1, 6, groups=64, bias=bias),\n",
        "      LinearBottleneck(64, 64, 1, 6, groups=64, bias=bias),\n",
        "    )\n",
        "    self.fifth_bottleneck = nn.Sequential(\n",
        "      LinearBottleneck(64, 96, 1, 6, groups=64, bias=bias),\n",
        "      LinearBottleneck(96, 96, 1, 6, groups=96, bias=bias),\n",
        "      LinearBottleneck(96, 96, 1, 6, groups=96, bias=bias),\n",
        "    )\n",
        "    self.sixth_bottleneck = nn.Sequential(\n",
        "      LinearBottleneck(96, 160, 2, 6, groups=96, bias=bias),\n",
        "      LinearBottleneck(160, 160, 1, 6, groups=160, bias=bias),\n",
        "      LinearBottleneck(160, 160, 1, 6, groups=160, bias=bias),\n",
        "    )\n",
        "    self.seventh_bottleneck = nn.Sequential(\n",
        "      LinearBottleneck(160, 320, 1, 6, groups=160, bias=bias),\n",
        "    )\n",
        "    self.pointwise_conv = nn.Sequential(\n",
        "      nn.Conv2d(320, 1280, kernel_size=1, bias=bias),\n",
        "      nn.BatchNorm2d(1280),\n",
        "      nn.ReLU6(inplace=True),\n",
        "    )\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=7)\n",
        "    self.classifier = nn.Linear(1280, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.x = x\n",
        "    x = self.first_layer(x)\n",
        "    x = self.first_bottleneck(x)\n",
        "    x = self.second_bottleneck(x)\n",
        "    x = self.third_bottleneck(x)\n",
        "    x = self.fourth_bottleneck(x)\n",
        "    x = self.fifth_bottleneck(x)\n",
        "    x = self.sixth_bottleneck(x)\n",
        "    x = self.seventh_bottleneck(x)\n",
        "    x = self.pointwise_conv(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "HPD3ATrb7h8Z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY7CqTuw7h-6",
        "outputId": "4f65b3ba-9b63-4528-d23d-8773ed6ae0c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MobileNetV2()\n",
        "from torchvision import models\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "UfuspKYq7iB1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model,(3,224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epUfBpP1qZtB",
        "outputId": "cbd548f9-f907-497c-d51a-944b3496aa16"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "             ReLU6-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 112, 112]           1,024\n",
            "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
            "             ReLU6-6         [-1, 32, 112, 112]               0\n",
            "            Conv2d-7         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-8         [-1, 32, 112, 112]              64\n",
            "             ReLU6-9         [-1, 32, 112, 112]               0\n",
            "           Conv2d-10         [-1, 16, 112, 112]             512\n",
            "      BatchNorm2d-11         [-1, 16, 112, 112]              32\n",
            "            ReLU6-12         [-1, 16, 112, 112]               0\n",
            " LinearBottleneck-13         [-1, 16, 112, 112]               0\n",
            "           Conv2d-14         [-1, 96, 112, 112]           1,536\n",
            "      BatchNorm2d-15         [-1, 96, 112, 112]             192\n",
            "            ReLU6-16         [-1, 96, 112, 112]               0\n",
            "           Conv2d-17           [-1, 96, 56, 56]           5,184\n",
            "      BatchNorm2d-18           [-1, 96, 56, 56]             192\n",
            "            ReLU6-19           [-1, 96, 56, 56]               0\n",
            "           Conv2d-20           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-21           [-1, 24, 56, 56]              48\n",
            "            ReLU6-22           [-1, 24, 56, 56]               0\n",
            " LinearBottleneck-23           [-1, 24, 56, 56]               0\n",
            "           Conv2d-24          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-25          [-1, 144, 56, 56]             288\n",
            "            ReLU6-26          [-1, 144, 56, 56]               0\n",
            "           Conv2d-27          [-1, 144, 56, 56]           7,776\n",
            "      BatchNorm2d-28          [-1, 144, 56, 56]             288\n",
            "            ReLU6-29          [-1, 144, 56, 56]               0\n",
            "           Conv2d-30           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-31           [-1, 24, 56, 56]              48\n",
            "            ReLU6-32           [-1, 24, 56, 56]               0\n",
            " LinearBottleneck-33           [-1, 24, 56, 56]               0\n",
            "           Conv2d-34          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-35          [-1, 144, 56, 56]             288\n",
            "            ReLU6-36          [-1, 144, 56, 56]               0\n",
            "           Conv2d-37          [-1, 144, 28, 28]           7,776\n",
            "      BatchNorm2d-38          [-1, 144, 28, 28]             288\n",
            "            ReLU6-39          [-1, 144, 28, 28]               0\n",
            "           Conv2d-40           [-1, 32, 28, 28]           4,608\n",
            "      BatchNorm2d-41           [-1, 32, 28, 28]              64\n",
            "            ReLU6-42           [-1, 32, 28, 28]               0\n",
            " LinearBottleneck-43           [-1, 32, 28, 28]               0\n",
            "           Conv2d-44          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-45          [-1, 192, 28, 28]             384\n",
            "            ReLU6-46          [-1, 192, 28, 28]               0\n",
            "           Conv2d-47          [-1, 192, 28, 28]          10,368\n",
            "      BatchNorm2d-48          [-1, 192, 28, 28]             384\n",
            "            ReLU6-49          [-1, 192, 28, 28]               0\n",
            "           Conv2d-50           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-51           [-1, 32, 28, 28]              64\n",
            "            ReLU6-52           [-1, 32, 28, 28]               0\n",
            " LinearBottleneck-53           [-1, 32, 28, 28]               0\n",
            "           Conv2d-54          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-55          [-1, 192, 28, 28]             384\n",
            "            ReLU6-56          [-1, 192, 28, 28]               0\n",
            "           Conv2d-57          [-1, 192, 28, 28]          10,368\n",
            "      BatchNorm2d-58          [-1, 192, 28, 28]             384\n",
            "            ReLU6-59          [-1, 192, 28, 28]               0\n",
            "           Conv2d-60           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-61           [-1, 32, 28, 28]              64\n",
            "            ReLU6-62           [-1, 32, 28, 28]               0\n",
            " LinearBottleneck-63           [-1, 32, 28, 28]               0\n",
            "           Conv2d-64          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-65          [-1, 192, 28, 28]             384\n",
            "            ReLU6-66          [-1, 192, 28, 28]               0\n",
            "           Conv2d-67          [-1, 192, 14, 14]          10,368\n",
            "      BatchNorm2d-68          [-1, 192, 14, 14]             384\n",
            "            ReLU6-69          [-1, 192, 14, 14]               0\n",
            "           Conv2d-70           [-1, 64, 14, 14]          12,288\n",
            "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
            "            ReLU6-72           [-1, 64, 14, 14]               0\n",
            " LinearBottleneck-73           [-1, 64, 14, 14]               0\n",
            "           Conv2d-74          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-75          [-1, 384, 14, 14]             768\n",
            "            ReLU6-76          [-1, 384, 14, 14]               0\n",
            "           Conv2d-77          [-1, 384, 14, 14]          20,736\n",
            "      BatchNorm2d-78          [-1, 384, 14, 14]             768\n",
            "            ReLU6-79          [-1, 384, 14, 14]               0\n",
            "           Conv2d-80           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-81           [-1, 64, 14, 14]             128\n",
            "            ReLU6-82           [-1, 64, 14, 14]               0\n",
            " LinearBottleneck-83           [-1, 64, 14, 14]               0\n",
            "           Conv2d-84          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-85          [-1, 384, 14, 14]             768\n",
            "            ReLU6-86          [-1, 384, 14, 14]               0\n",
            "           Conv2d-87          [-1, 384, 14, 14]          20,736\n",
            "      BatchNorm2d-88          [-1, 384, 14, 14]             768\n",
            "            ReLU6-89          [-1, 384, 14, 14]               0\n",
            "           Conv2d-90           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-91           [-1, 64, 14, 14]             128\n",
            "            ReLU6-92           [-1, 64, 14, 14]               0\n",
            " LinearBottleneck-93           [-1, 64, 14, 14]               0\n",
            "           Conv2d-94          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
            "            ReLU6-96          [-1, 384, 14, 14]               0\n",
            "           Conv2d-97          [-1, 384, 14, 14]          20,736\n",
            "      BatchNorm2d-98          [-1, 384, 14, 14]             768\n",
            "            ReLU6-99          [-1, 384, 14, 14]               0\n",
            "          Conv2d-100           [-1, 64, 14, 14]          24,576\n",
            "     BatchNorm2d-101           [-1, 64, 14, 14]             128\n",
            "           ReLU6-102           [-1, 64, 14, 14]               0\n",
            "LinearBottleneck-103           [-1, 64, 14, 14]               0\n",
            "          Conv2d-104          [-1, 384, 14, 14]          24,576\n",
            "     BatchNorm2d-105          [-1, 384, 14, 14]             768\n",
            "           ReLU6-106          [-1, 384, 14, 14]               0\n",
            "          Conv2d-107          [-1, 384, 14, 14]          20,736\n",
            "     BatchNorm2d-108          [-1, 384, 14, 14]             768\n",
            "           ReLU6-109          [-1, 384, 14, 14]               0\n",
            "          Conv2d-110           [-1, 96, 14, 14]          36,864\n",
            "     BatchNorm2d-111           [-1, 96, 14, 14]             192\n",
            "           ReLU6-112           [-1, 96, 14, 14]               0\n",
            "LinearBottleneck-113           [-1, 96, 14, 14]               0\n",
            "          Conv2d-114          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-115          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-116          [-1, 576, 14, 14]               0\n",
            "          Conv2d-117          [-1, 576, 14, 14]          31,104\n",
            "     BatchNorm2d-118          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-119          [-1, 576, 14, 14]               0\n",
            "          Conv2d-120           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-121           [-1, 96, 14, 14]             192\n",
            "           ReLU6-122           [-1, 96, 14, 14]               0\n",
            "LinearBottleneck-123           [-1, 96, 14, 14]               0\n",
            "          Conv2d-124          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-125          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-126          [-1, 576, 14, 14]               0\n",
            "          Conv2d-127          [-1, 576, 14, 14]          31,104\n",
            "     BatchNorm2d-128          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-129          [-1, 576, 14, 14]               0\n",
            "          Conv2d-130           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-131           [-1, 96, 14, 14]             192\n",
            "           ReLU6-132           [-1, 96, 14, 14]               0\n",
            "LinearBottleneck-133           [-1, 96, 14, 14]               0\n",
            "          Conv2d-134          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-135          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-136          [-1, 576, 14, 14]               0\n",
            "          Conv2d-137            [-1, 576, 7, 7]          31,104\n",
            "     BatchNorm2d-138            [-1, 576, 7, 7]           1,152\n",
            "           ReLU6-139            [-1, 576, 7, 7]               0\n",
            "          Conv2d-140            [-1, 160, 7, 7]          92,160\n",
            "     BatchNorm2d-141            [-1, 160, 7, 7]             320\n",
            "           ReLU6-142            [-1, 160, 7, 7]               0\n",
            "LinearBottleneck-143            [-1, 160, 7, 7]               0\n",
            "          Conv2d-144            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-145            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-146            [-1, 960, 7, 7]               0\n",
            "          Conv2d-147            [-1, 960, 7, 7]          51,840\n",
            "     BatchNorm2d-148            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-149            [-1, 960, 7, 7]               0\n",
            "          Conv2d-150            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-151            [-1, 160, 7, 7]             320\n",
            "           ReLU6-152            [-1, 160, 7, 7]               0\n",
            "LinearBottleneck-153            [-1, 160, 7, 7]               0\n",
            "          Conv2d-154            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-155            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-156            [-1, 960, 7, 7]               0\n",
            "          Conv2d-157            [-1, 960, 7, 7]          51,840\n",
            "     BatchNorm2d-158            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-159            [-1, 960, 7, 7]               0\n",
            "          Conv2d-160            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-161            [-1, 160, 7, 7]             320\n",
            "           ReLU6-162            [-1, 160, 7, 7]               0\n",
            "LinearBottleneck-163            [-1, 160, 7, 7]               0\n",
            "          Conv2d-164            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-165            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-166            [-1, 960, 7, 7]               0\n",
            "          Conv2d-167            [-1, 960, 7, 7]          51,840\n",
            "     BatchNorm2d-168            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-169            [-1, 960, 7, 7]               0\n",
            "          Conv2d-170            [-1, 320, 7, 7]         307,200\n",
            "     BatchNorm2d-171            [-1, 320, 7, 7]             640\n",
            "           ReLU6-172            [-1, 320, 7, 7]               0\n",
            "LinearBottleneck-173            [-1, 320, 7, 7]               0\n",
            "          Conv2d-174           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-175           [-1, 1280, 7, 7]           2,560\n",
            "           ReLU6-176           [-1, 1280, 7, 7]               0\n",
            "       AvgPool2d-177           [-1, 1280, 1, 1]               0\n",
            "          Linear-178                   [-1, 10]          12,810\n",
            "================================================================\n",
            "Total params: 2,557,450\n",
            "Trainable params: 2,557,450\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 166.41\n",
            "Params size (MB): 9.76\n",
            "Estimated Total Size (MB): 176.74\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
        "        break  "
      ],
      "metadata": {
        "id": "q2BSSmiW7iEj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    print('images.shape:', images.shape)\n",
        "    out = model(images)\n",
        "    print('out.shape:', out.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "p8LXBpwL7iHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb76c8a-3628-4174-864d-77815da304db"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images.shape: torch.Size([64, 3, 224, 224])\n",
            "out.shape: torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "metadata": {
        "id": "Wqfeb7717iKB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "metadata": {
        "id": "S1huY2Sx7iMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0add3f7-5dcb-4d13-98f1-1255521268c4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "test_loader = DeviceDataLoader(test_loader, device)\n",
        "to_device(model, device);"
      ],
      "metadata": {
        "id": "TfB2KJ617iPh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "GgXnYONK7iSe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = to_device(MobileNetV2(), device)\n"
      ],
      "metadata": {
        "id": "WYPVHguM7iVI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, test_loader)"
      ],
      "metadata": {
        "id": "8lNJUght7iX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc99334-4fb0-4f7d-a449-b82bd639fdce"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_acc': 0.09982085973024368, 'val_loss': 2.302661180496216}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "khvWWvEE7ia9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = fit(num_epochs, lr, model, train_loader, test_loader, opt_func)"
      ],
      "metadata": {
        "id": "E7jNfoFh7id6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs')"
      ],
      "metadata": {
        "id": "xmRrDYAM7igk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history)"
      ],
      "metadata": {
        "id": "7HRR59To7ijR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs')"
      ],
      "metadata": {
        "id": "L28yY10O7imM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(history)"
      ],
      "metadata": {
        "id": "BfUCmriL7io4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(img, model):\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "    return datasets.classes[preds[0].item()]"
      ],
      "metadata": {
        "id": "qWsbkAR97ird"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "57pGbiVlvTLS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}