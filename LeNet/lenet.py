# -*- coding: utf-8 -*-
"""LeNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kx5ETZL5bglHpov-Boucd-Xv2Qcrs8l_
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class ImageClassificationBase(nn.Module):
    def training_step(self, batch):
        images, labels = batch 
        out = self(images)                  # Generate predictions
        loss = F.cross_entropy(out, labels) # Calculate loss
        acc = accuracy(out, labels) # Calculate accuracy
        return {'train_loss': loss.detach(), 'train_acc': acc}
    
    def validation_step(self, batch):
        images, labels = batch 
        out = self(images)                    # Generate predictions
        loss = F.cross_entropy(out, labels)   # Calculate loss
        acc = accuracy(out, labels)           # Calculate accuracy
        return {'val_loss': loss.detach(), 'val_acc': acc}
        
    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies
        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}
    
    def epoch_end(self, epoch, result):
        print("Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}".format(
            epoch, result['train_loss'], result['val_loss'], result['val_acc']))

class LeNet(ImageClassificationBase):
  def __init__(self, input_channels = 1):
    super(LeNet, self).__init__()
    self.block_1 = nn.Sequential(
      nn.Conv2d(input_channels, 6, kernel_size = 5, stride = 1, padding = 0, bias = False),
      nn.BatchNorm2d(6),
      nn.Tanh(),
      nn.AvgPool2d(kernel_size = 2, stride = 2),
      nn.Conv2d(6, 16, kernel_size = 5, stride = 1, padding = 0, bias = False),
      nn.BatchNorm2d(16),
      nn.Tanh(),
      nn.AvgPool2d(kernel_size = 2, stride = 2),
      nn.Conv2d(16, 120, kernel_size = 5, stride = 1, padding = 0, bias = False),
      nn.BatchNorm2d(120),
      nn.Tanh(),
    )
    self.linear_1 = nn.Linear(120, 84)
    self.linear_2 = nn.Linear(84, 10)
    self.softmax = nn.Softmax(dim = 1)

  def forward(self, x):
    x = self.block_1(x)
    x = x.view(x.size(0), -1)
    x = self.linear_1(x)
    x = self.linear_2(x)
    x = self.softmax(x)
    return x

import torch
import torch.nn as nn
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision import transforms
from torchvision.transforms import ToTensor
from torchvision.transforms import Resize
import matplotlib.pyplot as plt
import torch.nn.functional as F
import torch.optim as optim
from torchvision.transforms import ToTensor, Normalize, Compose
from torch.utils.data.dataloader import DataLoader

batch_size=128

train_data = datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=transforms.Compose(
        [
        Resize(size = (32,32)),
        ToTensor(),
        ]
    )
)

test_data = datasets.FashionMNIST(
    root="data",
    train=False,
    download=True,
    transform=transforms.Compose(
        [
        Resize(size = (32,32)),
        ToTensor(),
        ]
    )
)

train_dl = DataLoader(train_data, batch_size, shuffle=True)
val_dl = DataLoader(test_data, batch_size*2)
        
def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))

@torch.no_grad()
def evaluate(model, val_loader):
    model.eval()
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)

def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):
    history = []
    optimizer = opt_func(model.parameters(), lr)
    for epoch in range(epochs):
        # Training Phase 
        model.train()
        train_losses = []
        for batch in train_loader:
            loss = model.training_step(batch)
            train_losses.append(loss)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        # Validation phase
        result = evaluate(model, val_loader)
        result['train_loss'] = torch.stack(train_losses).mean().item()
        model.epoch_end(epoch, result)
        history.append(result)
    return history

img, label = train_data[0]

img.size()

model = LeNet()
from torchvision import models
from torchsummary import summary

print(summary(model,(1, 32, 32)))

model = LeNet()

num_epochs = 50
opt_func = torch.optim.Adam
lr = 0.001

fit(num_epochs, lr, model, train_dl, val_dl, opt_func)





